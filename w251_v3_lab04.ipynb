{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w251_v3_lab04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sotoodaa-ucb/ucb_mids_w251_homework_4/blob/main/w251_v3_lab04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0Ej9327K46p"
      },
      "source": [
        "In this lab we will experiment with some of the deep learning concepts covered in the async material, and beyond. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eefV8lZLPts",
        "outputId": "8f023519-d37f-4895-9aac-996fd4f1f9f7"
      },
      "source": [
        "# Import necessary packages. \n",
        "import torch, torch.nn as nn\n",
        "from PIL import Image\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa71b425270>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2zGYLpWRwPc"
      },
      "source": [
        "### MSE Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6U5hq8rL8g3",
        "outputId": "06e614d1-c09a-4a1a-c069-68950e319124"
      },
      "source": [
        "ypred = torch.arange(-5, 5).float()\n",
        "yact = torch.randint(2, (len(ypred),)).float()\n",
        "print(f'Dummy predicted values : {ypred}')\n",
        "print(f'Dummy actual values : {yact}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy predicted values : tensor([-5., -4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.])\n",
            "Dummy actual values : tensor([1., 1., 0., 0., 1., 1., 1., 1., 1., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWOJdMGOQipr",
        "outputId": "9d3d5355-7e48-44a4-b821-1959f433b982"
      },
      "source": [
        "criterion = torch.nn.MSELoss(reduction='none')\n",
        "loss = criterion(ypred, yact)\n",
        "print(f'MSE loss for each element {loss}')\n",
        "criterion = torch.nn.MSELoss(reduction='mean')\n",
        "loss = criterion(ypred, yact)\n",
        "print(f'MSE loss averaged {loss:.5f}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE loss for each element tensor([36., 25.,  9.,  4.,  4.,  1.,  0.,  1.,  4., 16.])\n",
            "MSE loss averaged 10.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdaVQIjrRyDv"
      },
      "source": [
        "### Binary Cross Entropy Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d2sa3zaR298",
        "outputId": "66481cfd-35ec-4e0d-f16b-966c6971f32d"
      },
      "source": [
        "ypred = torch.rand(10).float()\n",
        "yact = torch.randint(2, (len(ypred),)).float()\n",
        "print(f'Dummy predicted values : {ypred}')\n",
        "print(f'Dummy actual values : {yact}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy predicted values : tensor([0.6387, 0.5247, 0.6826, 0.3051, 0.4635, 0.4550, 0.5725, 0.4980, 0.9371,\n",
            "        0.6556])\n",
            "Dummy actual values : tensor([0., 1., 0., 0., 1., 0., 0., 0., 1., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajQhLBkb1HhS"
      },
      "source": [
        "Find the Binary Cross Entropy loss between the two vectors.\n",
        "You can find the loss functions [here](https://pytorch.org/docs/stable/nn.html).  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwAbwAr81tOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0858fae1-8146-411f-dcdc-9e813c331221"
      },
      "source": [
        "# Binaray Cross entropy loss....\n",
        "criterion = torch.nn.BCELoss(reduction='mean')\n",
        "loss = criterion(ypred, yact)\n",
        "print(f'BCELoss: {loss}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BCELoss: 0.7220292091369629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjZGDAri1zFc"
      },
      "source": [
        "### Multi Layer Perceptron Forward Pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5D0uaGV2h-M"
      },
      "source": [
        "# Lets initialise a MLP \n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(2, 2, bias = False), \n",
        "            nn.Linear(2, 1, bias = False))\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azBaCsap3Me8"
      },
      "source": [
        "net1 = MLP()\n",
        "x = torch.rand(2).float()\n",
        "with torch.no_grad(): out = net1(x)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwvD7e1f4e7P",
        "outputId": "81a3613c-ef8c-44c0-e4e6-b9afa605e537"
      },
      "source": [
        "print(f'Input to net : {x}')\n",
        "print('-'*50)\n",
        "print(f'Layer 0 parameters {net1.layers[0].weight}')\n",
        "print(f'Layer 1 parameters {net1.layers[1].weight}')\n",
        "print('-'*50)\n",
        "print(f'Output : {out}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input to net : tensor([0.9391, 0.4167])\n",
            "--------------------------------------------------\n",
            "Layer 0 parameters Parameter containing:\n",
            "tensor([[ 0.1975,  0.6707],\n",
            "        [ 0.4667, -0.6443]], requires_grad=True)\n",
            "Layer 1 parameters Parameter containing:\n",
            "tensor([[-0.6723, -0.3411]], requires_grad=True)\n",
            "--------------------------------------------------\n",
            "Output : tensor([-0.3705])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU-GjDpj9QDf"
      },
      "source": [
        "Can you calculate through matrix multiplication ?   \n",
        "Tip, you can use the torch.matmul function to multiply matrices, or alternatively check [this](https://stackoverflow.com/questions/60275705/how-to-calculate-a-forward-pass-with-matrix-operations-in-pytorch) link for calculating a forward pass. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWqHluq87YM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d41598de-045a-4cd5-89d8-8e63dcbab7dc"
      },
      "source": [
        "# You can enter your calculations here. \n",
        "net1.layers[1].weight @ (net1.layers[0].weight @ x)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.3705], grad_fn=<MvBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY9btQJ-46B8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V93t3NfX-GXa"
      },
      "source": [
        "### Multi Layer Perceptron Forward Pass with bias term\n",
        "If we add the bias term can you calculate to forward pass now ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70hdVk_X8YBN"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(2, 2, bias = True), \n",
        "            #nn.ReLU(),\n",
        "            nn.Linear(2, 1, bias = True))\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2soIoUFA7wro"
      },
      "source": [
        "net2 = MLP()\n",
        "with torch.no_grad(): out = net2(x)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e10yvyLP6wvG",
        "outputId": "b0f3b8fc-3b33-4792-8eba-a2b1031558bc"
      },
      "source": [
        "print(f'Input to net : {x}')\n",
        "print('-'*50)\n",
        "print(f'Layer 0 parameters {net2.layers[0].weight}')\n",
        "print(f'Layer 0 bias       {net2.layers[0].bias}\\n')\n",
        "print(f'Layer 1 parameters {net2.layers[1].weight}')\n",
        "print(f'Layer 1 bias       {net2.layers[1].bias}\\n')\n",
        "print('-'*50)\n",
        "print(f'Output : {out}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input to net : tensor([0.9391, 0.4167])\n",
            "--------------------------------------------------\n",
            "Layer 0 parameters Parameter containing:\n",
            "tensor([[-0.3725,  0.3635],\n",
            "        [-0.3753,  0.2080]], requires_grad=True)\n",
            "Layer 0 bias       Parameter containing:\n",
            "tensor([-0.2042, -0.0775], requires_grad=True)\n",
            "\n",
            "Layer 1 parameters Parameter containing:\n",
            "tensor([[-0.6798, -0.3371]], requires_grad=True)\n",
            "Layer 1 bias       Parameter containing:\n",
            "tensor([0.3837], requires_grad=True)\n",
            "\n",
            "--------------------------------------------------\n",
            "Output : tensor([0.7731])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldn3WAhJ-eQC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9c682f-5fe0-474e-dd4a-d18813fdf059"
      },
      "source": [
        "# You can enter your calculations here. \n",
        "print(net2.layers[1].weight.dim())\n",
        "print(net2.layers[1].bias.dim())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td2diDZd_Xqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d291a6c-5b2d-47fe-aee7-119c517832e7"
      },
      "source": [
        "# You can enter your calculations here. \n",
        "(net2.layers[1].weight @ (net2.layers[0].weight @ x + + net2.layers[0].bias) + + net2.layers[1].bias)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7731], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdyAZWJlAacs"
      },
      "source": [
        "### Multi Layer Perceptron Forward Pass with Relu\n",
        "If we add a RELU activation, can you calculate the forward pass now ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q19RFTcXAdHf"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(2, 2, bias = True), \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2, 1, bias = True))\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnqYBt_5Ahsq"
      },
      "source": [
        "net3 = MLP()\n",
        "with torch.no_grad(): out = net3(x)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHKF-GjpAlPq",
        "outputId": "d50c658d-72fc-4ab4-d0eb-9498b6ac8eae"
      },
      "source": [
        "print(f'Input to net : {x}')\n",
        "print('-'*50)\n",
        "print(f'Layer 0 parameters {net3.layers[0].weight}')\n",
        "print(f'Layer 0 bias       {net3.layers[0].bias}\\n')\n",
        "print(f'Layer 1 parameters {net3.layers[2].weight}')\n",
        "print(f'Layer 1 bias       {net3.layers[2].bias}\\n')\n",
        "print('-'*50)\n",
        "print(f'Output : {out}')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input to net : tensor([0.9391, 0.4167])\n",
            "--------------------------------------------------\n",
            "Layer 0 parameters Parameter containing:\n",
            "tensor([[ 0.4293,  0.6271],\n",
            "        [-0.3964, -0.1164]], requires_grad=True)\n",
            "Layer 0 bias       Parameter containing:\n",
            "tensor([-0.0137,  0.1033], requires_grad=True)\n",
            "\n",
            "Layer 1 parameters Parameter containing:\n",
            "tensor([[-0.5366, -0.5018]], requires_grad=True)\n",
            "Layer 1 bias       Parameter containing:\n",
            "tensor([0.3847], requires_grad=True)\n",
            "\n",
            "--------------------------------------------------\n",
            "Output : tensor([0.0354])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0iWatl0Avxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ec5d34-3030-4ede-da64-e2ddb5ff767a"
      },
      "source": [
        "# You can enter your calculations here. \n",
        "relu = torch.nn.ReLU()\n",
        "\n",
        "l1_fp = relu((net3.layers[0].weight @ x) + net3.layers[0].bias)\n",
        "l2_fp = relu((net3.layers[2].weight @ l1_fp) + net3.layers[2].bias)\n",
        "\n",
        "l2_fp"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0354], grad_fn=<ReluBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}